{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0924855f-3053-4bbf-bf25-b2576da2346a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- STUDENT ATTENTION REPORT -----\n",
      "\n",
      "\n",
      "----- STUDENT ATTENTION REPORT -----\n",
      "\n",
      "Student 0:\n",
      "  Left Turns    : 45\n",
      "  Right Turns   : 51\n",
      "  Center Frames : 220\n",
      "  Total Frames  : 316\n",
      "  Distraction   : 30.38%\n",
      "  Status        : ATTENTIVE\n",
      "\n",
      "Student 1:\n",
      "  Left Turns    : 120\n",
      "  Right Turns   : 98\n",
      "  Center Frames : 100\n",
      "  Total Frames  : 318\n",
      "  Distraction   : 68.55%\n",
      "  Status        : NOT ATTENTIVE\n",
      "\n",
      "Student 2:\n",
      "  Left Turns    : 122\n",
      "  Right Turns   : 98\n",
      "  Center Frames : 100\n",
      "  Total Frames  : 320\n",
      "  Distraction   : 68.75%\n",
      "  Status        : NOT ATTENTIVE\n",
      "\n",
      "Student 3:\n",
      "  Left Turns    : 124\n",
      "  Right Turns   : 98\n",
      "  Center Frames : 100\n",
      "  Total Frames  : 322\n",
      "  Distraction   : 68.94%\n",
      "  Status        : NOT ATTENTIVE\n",
      "\n",
      "Student 4:\n",
      "  Left Turns    : 126\n",
      "  Right Turns   : 98\n",
      "  Center Frames : 100\n",
      "  Total Frames  : 324\n",
      "  Distraction   : 69.14%\n",
      "  Status        : NOT ATTENTIVE\n",
      "\n",
      "Student 5:\n",
      "  Left Turns    : 128\n",
      "  Right Turns   : 98\n",
      "  Center Frames : 100\n",
      "  Total Frames  : 326\n",
      "  Distraction   : 69.33%\n",
      "  Status        : NOT ATTENTIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "VIDEO_PATH = \"classroom.mp4\"\n",
    "YAW_THRESHOLD = 15        # degrees\n",
    "DISTRACTION_LIMIT = 50   # percent\n",
    "\n",
    "# -----------------------------\n",
    "# MEDIAPIPE SETUP\n",
    "# -----------------------------\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=10,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# DATA STRUCTURE\n",
    "# -----------------------------\n",
    "students = {}\n",
    "\n",
    "# -----------------------------\n",
    "# VIDEO LOAD\n",
    "# -----------------------------\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = face_mesh.process(rgb)\n",
    "\n",
    "    # DEBUG: FACE COUNT\n",
    "    print(\"Faces detected:\", len(result.multi_face_landmarks) if result.multi_face_landmarks else 0)\n",
    "\n",
    "    if result.multi_face_landmarks:\n",
    "        for idx, face_landmarks in enumerate(result.multi_face_landmarks):\n",
    "\n",
    "            if idx not in students:\n",
    "                students[idx] = {\n",
    "                    \"left\": 0,\n",
    "                    \"right\": 0,\n",
    "                    \"center\": 0,\n",
    "                    \"total\": 0\n",
    "                }\n",
    "\n",
    "            nose = face_landmarks.landmark[1]\n",
    "            left_eye = face_landmarks.landmark[33]\n",
    "            right_eye = face_landmarks.landmark[263]\n",
    "\n",
    "            yaw = (right_eye.x - left_eye.x) * 100\n",
    "\n",
    "            if yaw > YAW_THRESHOLD:\n",
    "                students[idx][\"right\"] += 1\n",
    "            elif yaw < -YAW_THRESHOLD:\n",
    "                students[idx][\"left\"] += 1\n",
    "            else:\n",
    "                students[idx][\"center\"] += 1\n",
    "\n",
    "            students[idx][\"total\"] += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# -----------------------------\n",
    "# FINAL REPORT\n",
    "# -----------------------------\n",
    "print(\"\\n----- STUDENT ATTENTION REPORT -----\\n\")\n",
    "\n",
    "for student_id, data in students.items():\n",
    "    distracted = data[\"left\"] + data[\"right\"]\n",
    "    total = data[\"total\"]\n",
    "\n",
    "    distraction_percent = (distracted / total) * 100 if total > 0 else 0\n",
    "    status = \"ATTENTIVE\" if distraction_percent < DISTRACTION_LIMIT else \"NOT ATTENTIVE\"\n",
    "\n",
    "    print(f\"Student {student_id}:\")\n",
    "    print(f\"  Left Turns    : {data['left']}\")\n",
    "    print(f\"  Right Turns   : {data['right']}\")\n",
    "    print(f\"  Center Frames : {data['center']}\")\n",
    "    print(f\"  Total Frames  : {total}\")\n",
    "    print(f\"  Distraction   : {distraction_percent:.2f}%\")\n",
    "    print(f\"  Status        : {status}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c0abae-7dc0-4845-ad63-ae5e86c1213d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mp_env]",
   "language": "python",
   "name": "conda-env-mp_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
